{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "# importing libraries for data handling and analysis\n",
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from dateutil.parser import parse\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import string\n",
    "import timeit\n",
    "import sys\n",
    "import re\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, recall_score, log_loss\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import feature_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import cufflinks\n",
    "import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import chart_studio.plotly as py\n",
    "import plotly\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from openpyxl import load_workbook\n",
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# import js\n",
    "# from js import document, window, XMLHttpRequest, p5\n",
    "\n",
    "# importing libraries for data visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "color = sns.color_palette()\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# Standard plotly imports\n",
    "\n",
    "# Using plotly + cufflinks in offline mode\n",
    "cf.set_config_file(offline=True)\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Sklearn modules for preprocessing\n",
    "# from imblearn.over_sampling import SMOTE # SMOTE\n",
    "# sklearn module for ML model selection\n",
    "# import 'train_test_split'\n",
    "\n",
    "# libraries for data modelling\n",
    "\n",
    "# Common sklearn Model Helpers\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# sklearn modules for performance metrics\n",
    "\n",
    "# importing misceallenous libraries\n",
    "# ip = get_ipython()\n",
    "# ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# pwd\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "hr = pd.read_csv(r\".\\\\resources\\\\HR_dataset.csv\")\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# Headers\n",
    "hr.head(5)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# Columns\n",
    "hr.shape\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "hr.dtypes\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# checking for missing values\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "hr.isnull().values.any()\n",
    "# No missing Values\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Breaking Down columns by their various types\n",
    "hr.columns.to_series().groupby(hr.dtypes).groups\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# some statistics\n",
    "hr.describe()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "# number of employees that stayed and left the company\n",
    "hr['Attrition'].value_counts()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "# plotting histograms for the numerical columns or attributes\n",
    "hr.hist(figsize=(26, 26))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "(mu, sigma) = norm.fit(hr.loc[hr['Attrition'] == 'Yes', 'Age'])\n",
    "print(\n",
    "    'Ex-exmployees: average age = {:.1f} years old and standard deviation = {:.1f}'.format(mu, sigma))\n",
    "(mu, sigma) = norm.fit(hr.loc[hr['Attrition'] == 'No', 'Age'])\n",
    "print('Current exmployees: average age = {:.1f} years old and standard deviation = {:.1f}'.format(\n",
    "    mu, sigma))\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "# visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'Age']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'Age']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(title='Age Distribution in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[15, 60], dtick=5))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "# Education Field of employees\n",
    "hr['EducationField'].value_counts()\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "df_EducationField = pd.DataFrame(columns=[\"Field\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['EducationField'].unique()):\n",
    "    ratio = hr[(hr['EducationField'] == field) & (hr['Attrition'] ==\n",
    "                                                  \"Yes\")].shape[0] / hr[hr['EducationField'] == field].shape[0]\n",
    "    df_EducationField.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_EF = df_EducationField.groupby(by=\"Field\").sum()\n",
    "df_EF.iplot(kind='bar', title='Leavers by Education Field (%)')\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "# Gender of employees\n",
    "hr['Gender'].value_counts()\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "print(\"Normalised gender distribution of ex-employees in the dataset: Male = {:.1f}%; Female {:.1f}%.\".format((hr[(hr['Attrition'] == 'Yes')\n",
    "                                                                                                                  & (hr['Gender'] == 'Male')].shape[0] / hr[hr['Gender'] == 'Male'].shape[0])*100,\n",
    "                                                                                                              (hr[(hr['Attrition'] == 'Yes') & (hr['Gender'] == 'Female')].shape[0] / hr[hr['Gender'] == 'Female'].shape[0])*100))\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "df_Gender = pd.DataFrame(columns=[\"Gender\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['Gender'].unique()):\n",
    "    ratio = hr[(hr['Gender'] == field) & (hr['Attrition'] == \"Yes\")\n",
    "               ].shape[0] / hr[hr['Gender'] == field].shape[0]\n",
    "    df_Gender.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_g = df_Gender.groupby(by=\"Gender\").sum()\n",
    "df_g.iplot(kind='bar', title='Leavers by Gender (%)')\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# Marital Status of employees\n",
    "hr['MaritalStatus'].value_counts()\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "df_Marital = pd.DataFrame(columns=[\"Marital Status\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['MaritalStatus'].unique()):\n",
    "    ratio = hr[(hr['MaritalStatus'] == field) & (hr['Attrition'] ==\n",
    "                                                 \"Yes\")].shape[0] / hr[hr['MaritalStatus'] == field].shape[0]\n",
    "    df_Marital.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_M = df_Marital.groupby(by=\"Marital Status\").sum()\n",
    "df_M.iplot(kind='bar', title='Leavers by Marital Status (%)')\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "# Distance from Home\n",
    "print(\"Distance from home for employees to get to work is from {} to {} miles.\".format(hr['DistanceFromHome'].min(),\n",
    "                                                                                       hr['DistanceFromHome'].max()))\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "print('Average distance from home for currently active employees: {:.2f} miles and ex-employees: {:.2f} miles'.format(\n",
    "    hr[hr['Attrition'] == 'No']['DistanceFromHome'].mean(), hr[hr['Attrition'] == 'Yes']['DistanceFromHome'].mean()))\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'DistanceFromHome']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'DistanceFromHome']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(\n",
    "    title='Distance From Home Distribution in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 30], dtick=2))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# The organisation consists of several departments\n",
    "hr['Department'].value_counts()\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "df_Department = pd.DataFrame(columns=[\"Department\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['Department'].unique()):\n",
    "    ratio = hr[(hr['Department'] == field) & (hr['Attrition'] == \"Yes\")\n",
    "               ].shape[0] / hr[hr['Department'] == field].shape[0]\n",
    "    df_Department.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_D = df_Department.groupby(by=\"Department\").sum()\n",
    "df_D.iplot(kind='bar', title='Leavers by Department (%)')\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "# Employees have different business travel commitmnent depending on their roles and level in the organisation\n",
    "hr['BusinessTravel'].value_counts()\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "df_BusinessTravel = pd.DataFrame(columns=[\"Business Travel\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['BusinessTravel'].unique()):\n",
    "    ratio = hr[(hr['BusinessTravel'] == field) & (hr['Attrition'] ==\n",
    "                                                  \"Yes\")].shape[0] / hr[hr['BusinessTravel'] == field].shape[0]\n",
    "    df_BusinessTravel.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_B = df_BusinessTravel.groupby(by=\"Business Travel\").sum()\n",
    "df_B.iplot(kind='bar', title='Leavers by Business Travel (%)')\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "# Employees in the database have several roles on-file\n",
    "hr['JobRole'].value_counts()\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "df_JobRole = pd.DataFrame(columns=[\"Job Role\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['JobRole'].unique()):\n",
    "    ratio = hr[(hr['JobRole'] == field) & (hr['Attrition'] == \"Yes\")\n",
    "               ].shape[0] / hr[hr['JobRole'] == field].shape[0]\n",
    "    df_JobRole.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_JB = df_JobRole.groupby(by=\"Job Role\").sum()\n",
    "df_JB.iplot(kind='bar', title='Leavers by Job Role (%)')\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "hr['JobLevel'].value_counts()\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "df_JobLevel = pd.DataFrame(columns=[\"Job Level\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['JobLevel'].unique()):\n",
    "    ratio = hr[(hr['JobLevel'] == field) & (hr['Attrition'] == \"Yes\")\n",
    "               ].shape[0] / hr[hr['JobLevel'] == field].shape[0]\n",
    "    df_JobLevel.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_J = df_JobLevel.groupby(by=\"Job Level\").sum()\n",
    "df_J.iplot(kind='bar', title='Leavers by Job Level (%)')\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "hr['JobInvolvement'].value_counts()\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "df_JobInvolvement = pd.DataFrame(columns=[\"Job Involvement\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['JobInvolvement'].unique()):\n",
    "    ratio = hr[(hr['JobInvolvement'] == field) & (hr['Attrition'] ==\n",
    "                                                  \"Yes\")].shape[0] / hr[hr['JobInvolvement'] == field].shape[0]\n",
    "    df_JobInvolvement.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_JV = df_JobInvolvement.groupby(by=\"Job Involvement\").sum()\n",
    "df_JV.iplot(kind='bar', title='Leavers by Job Involvement (%)')\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "print(\"Number of training times last year varies from {} to {} years.\".format(\n",
    "    hr['TrainingTimesLastYear'].min(), hr['TrainingTimesLastYear'].max()))\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'TrainingTimesLastYear']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'TrainingTimesLastYear']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(\n",
    "    title='Training Times Last Year metric in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 6], dtick=1))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "hr['NumCompaniesWorked'].value_counts()\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "df_NumCompaniesWorked = pd.DataFrame(\n",
    "    columns=[\"Num Companies Worked\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['NumCompaniesWorked'].unique()):\n",
    "    ratio = hr[(hr['NumCompaniesWorked'] == field) & (hr['Attrition'] ==\n",
    "                                                      \"Yes\")].shape[0] / hr[hr['NumCompaniesWorked'] == field].shape[0]\n",
    "    df_NumCompaniesWorked.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_NW = df_NumCompaniesWorked.groupby(by=\"Num Companies Worked\").sum()\n",
    "df_NW.iplot(kind='bar', title='Leavers by Num Companies Worked (%)')\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "# Number of years in company\n",
    "print('Average Number of Years at the company for currently active employees: {:.2f} miles and ex-employees: {:.2f} years'.format(\n",
    "    hr[hr['Attrition'] == 'No']['YearsAtCompany'].mean(), hr[hr['Attrition'] == 'Yes']['YearsAtCompany'].mean()))\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "print(\"Number of Years at the company varies from {} to {} years.\".format(\n",
    "    hr['YearsAtCompany'].min(), hr['YearsAtCompany'].max()))\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'YearsAtCompany']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'YearsAtCompany']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(title='Years At Company in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 40], dtick=5))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "print(\"Number of Years in the current role varies from {} to {} years.\".format(\n",
    "    hr['YearsInCurrentRole'].min(), hr['YearsInCurrentRole'].max()))\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'YearsInCurrentRole']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'YearsInCurrentRole']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(\n",
    "    title='Years InCurrent Role in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 18], dtick=1))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "print(\"Number of Years since last promotion varies from {} to {} years.\".format(\n",
    "    hr['YearsSinceLastPromotion'].min(), hr['YearsSinceLastPromotion'].max()))\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'YearsSinceLastPromotion']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'YearsSinceLastPromotion']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(\n",
    "    title='Years Since Last Promotion in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 15], dtick=1))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "print(\"Total working years varies from {} to {} years.\".format(\n",
    "    hr['TotalWorkingYears'].min(), hr['TotalWorkingYears'].max()))\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'TotalWorkingYears']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'TotalWorkingYears']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(\n",
    "    title='Total Working Years in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 40], dtick=5))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "# Years working with current manager\n",
    "print('Average Number of Years with current manager for currently active employees: {:.2f} miles and ex-employees: {:.2f} years'.format(\n",
    "    hr[hr['Attrition'] == 'No']['YearsWithCurrManager'].mean(), hr[hr['Attrition'] == 'Yes']['YearsWithCurrManager'].mean()))\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "print(\"Number of Years with current manager varies from {} to {} years.\".format(\n",
    "    hr['YearsWithCurrManager'].min(), hr['YearsWithCurrManager'].max()))\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'YearsWithCurrManager']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'YearsWithCurrManager']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(\n",
    "    title='Years With Curr Manager in Percent by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 17], dtick=1))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "# Work-Life Balance Score\n",
    "hr['WorkLifeBalance'].value_counts()\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "df_WorkLifeBalance = pd.DataFrame(columns=[\"WorkLifeBalance\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['WorkLifeBalance'].unique()):\n",
    "    ratio = hr[(hr['WorkLifeBalance'] == field) & (hr['Attrition'] ==\n",
    "                                                   \"Yes\")].shape[0] / hr[hr['WorkLifeBalance'] == field].shape[0]\n",
    "    df_WorkLifeBalance.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_W = df_WorkLifeBalance.groupby(by=\"WorkLifeBalance\").sum()\n",
    "df_W.iplot(kind='bar', title='Leavers by WorkLifeBalance (%)')\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "hr['StandardHours'].value_counts()\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "hr['OverTime'].value_counts()\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "df_OverTime = pd.DataFrame(columns=[\"OverTime\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['OverTime'].unique()):\n",
    "    ratio = hr[(hr['OverTime'] == field) & (hr['Attrition'] == \"Yes\")\n",
    "               ].shape[0] / hr[hr['OverTime'] == field].shape[0]\n",
    "    df_OverTime.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_O = df_OverTime.groupby(by=\"OverTime\").sum()\n",
    "df_O.iplot(kind='bar', title='Leavers by OverTime (%)')\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "# Pay/Salary Employee Information\n",
    "print(\"Employee Hourly Rate varies from ${} to ${}.\".format(\n",
    "    hr['HourlyRate'].min(), hr['HourlyRate'].max()))\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "print(\"Employee Daily Rate varies from ${} to ${}.\".format(\n",
    "    hr['DailyRate'].min(), hr['DailyRate'].max()))\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "print(\"Employee Monthly Rate varies from ${} to ${}.\".format(\n",
    "    hr['MonthlyRate'].min(), hr['MonthlyRate'].max()))\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "print(\"Employee Monthly Income varies from ${} to ${}.\".format(\n",
    "    hr['MonthlyIncome'].min(), hr['MonthlyIncome'].max()))\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'MonthlyIncome']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'MonthlyIncome']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(title='Monthly Income by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[0, 20000], dtick=2000))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "print(\"Percentage Salary Hikes varies from {}% to {}%.\".format(\n",
    "    hr['PercentSalaryHike'].min(), hr['PercentSalaryHike'].max()))\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "x1 = hr.loc[hr['Attrition'] == 'No', 'PercentSalaryHike']\n",
    "x2 = hr.loc[hr['Attrition'] == 'Yes', 'PercentSalaryHike']\n",
    "# Group data together\n",
    "hist_data = [x1, x2]\n",
    "group_labels = ['Active Employees', 'Ex-Employees']\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         curve_type='kde', show_hist=False, show_rug=False)\n",
    "# Add title\n",
    "fig['layout'].update(title='Percent Salary Hike by Attrition Status')\n",
    "fig['layout'].update(xaxis=dict(range=[10, 26], dtick=1))\n",
    "# Plot\n",
    "plotly.offline.iplot(fig, filename='Distplot with Multiple Datasets')\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "print(\"Stock Option Levels varies from {} to {}.\".format(\n",
    "    hr['StockOptionLevel'].min(), hr['StockOptionLevel'].max()))\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "print(\"Normalised percentage of leavers by Stock Option Level: 1: {:.2f}%, 2: {:.2f}%, 3: {:.2f}%\".format(\n",
    "    hr[(hr['Attrition'] == 'Yes') & (hr['StockOptionLevel'] == 1)\n",
    "       ].shape[0] / hr[hr['StockOptionLevel'] == 1].shape[0]*100,\n",
    "    hr[(hr['Attrition'] == 'Yes') & (hr['StockOptionLevel'] == 2)\n",
    "       ].shape[0] / hr[hr['StockOptionLevel'] == 1].shape[0]*100,\n",
    "    hr[(hr['Attrition'] == 'Yes') & (hr['StockOptionLevel'] == 3)].shape[0] / hr[hr['StockOptionLevel'] == 1].shape[0]*100))\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "df_StockOptionLevel = pd.DataFrame(\n",
    "    columns=[\"StockOptionLevel\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['StockOptionLevel'].unique()):\n",
    "    ratio = hr[(hr['StockOptionLevel'] == field) & (hr['Attrition'] ==\n",
    "                                                    \"Yes\")].shape[0] / hr[hr['StockOptionLevel'] == field].shape[0]\n",
    "    df_StockOptionLevel.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_S = df_StockOptionLevel.groupby(by=\"StockOptionLevel\").sum()\n",
    "df_S.iplot(kind='bar', title='Leavers by Stock Option Level (%)')\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "# Employee Satisfaction and Performance Information\n",
    "# Environment Satisfaction was captured as: 1 'Low' 2 'Medium' 3 'High' 4 'Very High'.\n",
    "# Proportion of Leaving Employees decreases as the Environment Satisfaction score increases.\n",
    "hr['EnvironmentSatisfaction'].value_counts()\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "df_EnvironmentSatisfaction = pd.DataFrame(\n",
    "    columns=[\"EnvironmentSatisfaction\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['EnvironmentSatisfaction'].unique()):\n",
    "    ratio = hr[(hr['EnvironmentSatisfaction'] == field) & (hr['Attrition'] ==\n",
    "                                                           \"Yes\")].shape[0] / hr[hr['EnvironmentSatisfaction'] == field].shape[0]\n",
    "    df_EnvironmentSatisfaction.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_E = df_EnvironmentSatisfaction.groupby(by=\"EnvironmentSatisfaction\").sum()\n",
    "df_E.iplot(kind='bar', title='Leavers by Environment Satisfaction (%)')\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "# Job Satisfaction was captured as: 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
    "hr['JobSatisfaction'].value_counts()\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "df_JobSatisfaction = pd.DataFrame(columns=[\"JobSatisfaction\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['JobSatisfaction'].unique()):\n",
    "    ratio = hr[(hr['JobSatisfaction'] == field) & (hr['Attrition'] ==\n",
    "                                                   \"Yes\")].shape[0] / hr[hr['JobSatisfaction'] == field].shape[0]\n",
    "    df_JobSatisfaction.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_JF = df_JobSatisfaction.groupby(by=\"JobSatisfaction\").sum()\n",
    "df_JF.iplot(kind='bar', title='Leavers by Job Satisfaction (%)')\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "hr['RelationshipSatisfaction'].value_counts()\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "df_RelationshipSatisfaction = pd.DataFrame(\n",
    "    columns=[\"RelationshipSatisfaction\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['RelationshipSatisfaction'].unique()):\n",
    "    ratio = hr[(hr['RelationshipSatisfaction'] == field) & (hr['Attrition'] ==\n",
    "                                                            \"Yes\")].shape[0] / hr[hr['RelationshipSatisfaction'] == field].shape[0]\n",
    "    df_RelationshipSatisfaction.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_R = df_RelationshipSatisfaction.groupby(by=\"RelationshipSatisfaction\").sum()\n",
    "df_R.iplot(kind='bar', title='Leavers by Relationship Satisfaction (%)')\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "hr['PerformanceRating'].value_counts()\n",
    "\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "print(\"Normalised percentage of leavers by Stock Option Level: 3: {:.2f}%, 4: {:.2f}%\".format(\n",
    "    hr[(hr['Attrition'] == 'Yes') & (hr['PerformanceRating'] == 3)\n",
    "       ].shape[0] / hr[hr['StockOptionLevel'] == 1].shape[0]*100,\n",
    "    hr[(hr['Attrition'] == 'Yes') & (hr['PerformanceRating'] == 4)].shape[0] / hr[hr['StockOptionLevel'] == 1].shape[0]*100))\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "df_PerformanceRating = pd.DataFrame(\n",
    "    columns=[\"PerformanceRating\", \"% of Leavers\"])\n",
    "i = 0\n",
    "for field in list(hr['PerformanceRating'].unique()):\n",
    "    ratio = hr[(hr['PerformanceRating'] == field) & (hr['Attrition'] ==\n",
    "                                                     \"Yes\")].shape[0] / hr[hr['PerformanceRating'] == field].shape[0]\n",
    "    df_PerformanceRating.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "#print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))\n",
    "df_P = df_PerformanceRating.groupby(by=\"PerformanceRating\").sum()\n",
    "df_P.iplot(kind='bar', title='Leavers by Performance Rating (%)')\n",
    "\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "\n",
    "# Target Variable: Attrition\n",
    "# The feature 'Attrition' is what this Machine Learning problem is about. We are trying to predict the value of the feature\n",
    "# 'Attrition' by using other related features associated with the employee's personal and professional history.\n",
    "# Attrition indicates if the employee is currently active ('No') or has left the company ('Yes')\n",
    "hr['Attrition'].value_counts()\n",
    "\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "print(\"Percentage of Current Employees is {:.1f}% and of Ex-employees is: {:.1f}%\".format(\n",
    "    hr[hr['Attrition'] == 'No'].shape[0] / hr.shape[0]*100,\n",
    "    hr[hr['Attrition'] == 'Yes'].shape[0] / hr.shape[0]*100))\n",
    "\n",
    "\n",
    "# In[77]:\n",
    "\n",
    "\n",
    "# Add visualisation\n",
    "hr['Attrition'].iplot(kind='hist', xTitle='Attrition',\n",
    "                      yTitle='count', title='Attrition Distribution')\n",
    "\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "# As shown on the chart above, we see this is an imbalanced class problem.\n",
    "# Indeed, the percentage of Current Employees in our dataset is 83.9% and the percentage of Ex-employees is: 16.1%\n",
    "# Machine learning algorithms typically work best when the number of instances of each classes are roughly equal.\n",
    "# We will have to address this target feature imbalance prior to implementing our Machine Learning algorithms.\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "# Correlations (only linear corellations are measured)\n",
    "# Find correlations with the target and sort\n",
    "df_HR_TCOR = hr.copy()\n",
    "df_HR_TCOR['Target'] = df_HR_TCOR['Attrition'].apply(\n",
    "    lambda x: 0 if x == 'No' else 1)\n",
    "df_HR_TCOR = df_HR_TCOR.drop(\n",
    "    ['Attrition', 'EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1)\n",
    "correlations = df_HR_TCOR.corr()['Target'].sort_values()\n",
    "print('Most Positive Correlations: \\n', correlations.tail(5))\n",
    "print('\\nMost Negative Correlations: \\n', correlations.head(5))\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "# plotting a heatmap to visualize the correlation between Attrition and these factors\n",
    "# Calculate correlations\n",
    "corr = df_HR_TCOR.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr,\n",
    "            vmax=.5,\n",
    "            mask=mask,\n",
    "            # annot=True, fmt='.2f',\n",
    "            linewidths=.2, cmap=\"YlGnBu\")\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "# As shown above, \"Monthly Rate\", \"Number of Companies Worked\" and \"Distance From Home\" are positively correlated to Attrition;\n",
    "# while \"Total Working Years\", \"Job Level\", and \"Years In Current Role\" are negatively correlated to Attrition.\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "# before we move to the algorithm phase we need to remove useless columns or colums with only one unique value\n",
    "hr = hr.drop('StandardHours', axis=1)\n",
    "hr.head(2)\n",
    "# dropped columns (employeecount,over18,employeenumber,standard hours)\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "# Encoding\n",
    "# Machine learning Models can only work with numerical attributes, so we have to convert the categorical\n",
    "# labels with numeric values\n",
    "# label emcoding and one-hot encoding will be used\n",
    "En = LabelEncoder()\n",
    "# Label Encoding will be used for columns with 2 or less unique values\n",
    "En_count = 0\n",
    "for col in hr.columns[1:]:\n",
    "    if hr[col].dtype == 'object':\n",
    "        if len(list(hr[col].unique())) <= 2:\n",
    "            En.fit(hr[col])\n",
    "            hr[col] = En.transform(hr[col])\n",
    "            En_count += 1\n",
    "print('{} columns were label encoded.'.format(En_count))\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "# convert rest of categorical variable into dummy\n",
    "hr = pd.get_dummies(hr, drop_first=True)\n",
    "print(hr.shape)\n",
    "hr.head(2)\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "# Feature Scaling : this will shrink the range of values between o - n\n",
    "# as Machine Learning algorithms perform better\n",
    "# when input numerical variables fall within a similar scale\n",
    "scaler = MinMaxScaler(feature_range=(0, 5))\n",
    "hr_col = list(hr.columns)\n",
    "hr_col.remove('Attrition')\n",
    "for col in hr_col:\n",
    "    hr[col] = hr[col].astype(float)\n",
    "    hr[[col]] = scaler.fit_transform(hr[[col]])\n",
    "hr['Attrition'] = pd.to_numeric(hr['Attrition'], downcast='float')\n",
    "hr.head()\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "# Splitting the data\n",
    "# assign the target to a new dataframe and convert it to a numerical feature\n",
    "target = hr['Attrition'].copy()\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "type(target)\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "# let's remove the target feature and redundant features from the dataset\n",
    "hr.drop(['Attrition'], axis=1, inplace=True)\n",
    "print('Size of Full dataset is: {}'.format(hr.shape))\n",
    "\n",
    "\n",
    "# In[122]:\n",
    "\n",
    "\n",
    "# Since we have class imbalance (i.e. more employees with turnover=0 than turnover=1)\n",
    "# let's use stratify=y to maintain the same ratio as in the training dataset when splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(hr,\n",
    "                                                    target,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=target)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "\n",
    "\n",
    "# In[180]:\n",
    "\n",
    "\n",
    "# selection of algorithms to consider and set performance measure\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state=0,\n",
    "                                                         class_weight='balanced')))\n",
    "models.append(('Random Forest', RandomForestClassifier(\n",
    "    n_estimators=110, random_state=0)))\n",
    "models.append(('Gradient Boosting', GradientBoostingClassifier\n",
    "               (n_estimators=20, random_state=0)))\n",
    "\n",
    "\n",
    "# In[181]:\n",
    "\n",
    "\n",
    "# evaluating each model in turn and provide accuracy and standard deviation scores\n",
    "acc_R = []\n",
    "auc_R = []\n",
    "names = []\n",
    "# set table to table to populate with performance results\n",
    "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD',\n",
    "       'Accuracy Mean', 'Accuracy STD']\n",
    "df_R = pd.DataFrame(columns=col)\n",
    "i = 0\n",
    "# evaluate each model using cross-validation\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(\n",
    "        n_splits=10, random_state=0)  # 10-fold cross-validation\n",
    "\n",
    "    CV_ACC_R = model_selection.cross_val_score(  # accuracy scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    CV_ACC_R = model_selection.cross_val_score(  # roc_auc scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "\n",
    "    acc_R.append(CV_ACC_R)\n",
    "    auc_R.append(CV_ACC_R)\n",
    "    names.append(name)\n",
    "    df_R.loc[i] = [name,\n",
    "                   round(CV_ACC_R.mean()*100, 2),\n",
    "                   round(CV_ACC_R.std()*100, 2),\n",
    "                   round(CV_ACC_R.mean()*100, 2),\n",
    "                   round(CV_ACC_R.std()*100, 2)\n",
    "                   ]\n",
    "    i += 1\n",
    "df_R.sort_values(by=['ROC AUC Mean'], ascending=False)\n",
    "\n",
    "\n",
    "# In[124]:\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.suptitle('Algorithm Accuracy Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(acc_R)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[125]:\n",
    "\n",
    "\n",
    "# in this project there are not an equal number of observations in each class\n",
    "# and all predictions and prediction errors are equally important this is why Classification Accuracy metric is not suitable enough\n",
    "# let us try a different metric\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.suptitle('Algorithm ROC AUC Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(auc_R)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# we will be using both the logistic regression and the random forest\n",
    "\n",
    "\n",
    "# In[128]:\n",
    "\n",
    "\n",
    "# using 10 fold Cross-Validation to train our Logistic Regression Model and estimate its AUC score.\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=0)\n",
    "modelCV = LogisticRegression(solver='liblinear',\n",
    "                             class_weight=\"balanced\",\n",
    "                             random_state=0)\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(\n",
    "    modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"AUC score (STD): %.2f (%.2f)\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "# In[129]:\n",
    "\n",
    "\n",
    "# Fine tuning logic regession\n",
    "# hyper-parameter list to fine-tune\n",
    "param_grid = {'C': np.arange(1e-03, 2, 0.01)}\n",
    "log_gs = GridSearchCV(LogisticRegression(solver='liblinear',  # setting GridSearchCV\n",
    "                                         class_weight=\"balanced\",\n",
    "                                         random_state=0),\n",
    "                      iid=True,\n",
    "                      return_train_score=True,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='roc_auc',\n",
    "                      cv=10)\n",
    "\n",
    "log_grid = log_gs.fit(X_train, y_train)\n",
    "log_opt = log_grid.best_estimator_\n",
    "results = log_gs.cv_results_\n",
    "\n",
    "print('='*20)\n",
    "print(\"best params: \" + str(log_gs.best_estimator_))\n",
    "print(\"best params: \" + str(log_gs.best_params_))\n",
    "print('best score:', log_gs.best_score_)\n",
    "print('='*20)\n",
    "\n",
    "\n",
    "# In[131]:\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, log_opt.predict(X_test))\n",
    "class_names = [0, 1]  # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "\n",
    "print('Accuracy of Logistic Regression Classifier on test set: {:.2f}'.format(\n",
    "    log_opt.score(X_test, y_test)*100))\n",
    "\n",
    "\n",
    "# In[134]:\n",
    "\n",
    "\n",
    "# Classification report for the optimised Log Regression\n",
    "log_opt.fit(X_train, y_train)\n",
    "print(classification_report(y_test, log_opt.predict(X_test)))\n",
    "\n",
    "\n",
    "# In[187]:\n",
    "\n",
    "\n",
    "log_opt.fit(X_train, y_train)  # fit optimised model to the training data\n",
    "probs = log_opt.predict_proba(X_test)  # predict probabilities\n",
    "# we will only keep probabilities associated with the employee leaving\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC score using test dataset\n",
    "logit_roc_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC score: %.3f' % logit_roc_auc)\n",
    "\n",
    "\n",
    "# In[171]:\n",
    "\n",
    "\n",
    "# Based on our ROC AUC comparison analysis, Logistic Regression and Random Forest show the highest mean AUC scores\n",
    "# but we will use the random forest algorithm because\n",
    "# it allows us to know which features are of the most importance in predicting the target feature (\"attrition\")\n",
    "# fine-tuning the Random Forest algorithm's hyper-parameters by cross-validation against the AUC score\n",
    "rf_classifier = RandomForestClassifier(class_weight=\"balanced\",\n",
    "                                       random_state=0)\n",
    "param_grid = {'n_estimators': [110],\n",
    "              'min_samples_split': [8],\n",
    "              'min_samples_leaf': [1],\n",
    "              'max_depth': [15]}\n",
    "\n",
    "grid_obj = GridSearchCV(rf_classifier,\n",
    "                        iid=True,\n",
    "                        return_train_score=True,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='roc_auc',\n",
    "                        cv=10)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "rf_opt = grid_fit.best_estimator_\n",
    "\n",
    "print('='*20)\n",
    "print(\"best params: \" + str(grid_obj.best_estimator_))\n",
    "print(\"best params: \" + str(grid_obj.best_params_))\n",
    "print('best score:', grid_obj.best_score_)\n",
    "print('='*20)\n",
    "\n",
    "\n",
    "# In[155]:\n",
    "\n",
    "\n",
    "# ploting the features by their importance.\n",
    "importances = rf_opt.feature_importances_\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [X_train.columns[i] for i in indices]\n",
    "plt.figure(figsize=(15, 7))  # Create plot\n",
    "plt.title(\"Feature Importance\")  # Create plot title\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])  # Add bars\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "plt.show()  # Show plot\n",
    "\n",
    "\n",
    "# In[156]:\n",
    "\n",
    "\n",
    "# coeficient\n",
    "importances = rf_opt.feature_importances_\n",
    "df_param_coeff = pd.DataFrame(columns=['Feature', 'Coefficient'])\n",
    "for i in range(44):\n",
    "    feat = X_train.columns[i]\n",
    "    coeff = importances[i]\n",
    "    df_param_coeff.loc[i] = (feat, coeff)\n",
    "df_param_coeff.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "df_param_coeff = df_param_coeff.reset_index(drop=True)\n",
    "df_param_coeff.head(10)\n",
    "\n",
    "\n",
    "# In[157]:\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, rf_opt.predict(X_test))\n",
    "class_names = [0, 1]  # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# In[173]:\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy of RandomForest Regression Classifier on test set: {:.2f}'.format(\n",
    "    rf_opt.score(X_test, y_test)*100))\n",
    "\n",
    "\n",
    "# In[174]:\n",
    "\n",
    "\n",
    "# Classification report for the optimised RF Regression\n",
    "rf_opt.fit(X_train, y_train)\n",
    "print(classification_report(y_test, rf_opt.predict(X_test)))\n",
    "\n",
    "\n",
    "# In[183]:\n",
    "\n",
    "\n",
    "# checking auc score\n",
    "rf_opt.fit(X_train, y_train)  # fit optimised model to the training data\n",
    "probs = rf_opt.predict_proba(X_test)  # predict probabilities\n",
    "# we will only keep probabilities associated with the employee leaving\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC score using test dataset\n",
    "rf_opt_roc_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC score: %.3f' % rf_opt_roc_auc)\n",
    "\n",
    "\n",
    "# In[190]:\n",
    "\n",
    "\n",
    "# Create ROC Graph\n",
    "fpr, tpr, thresholds = roc_curve(y_test, log_opt.predict_proba(X_test)[:, 1])\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(\n",
    "    y_test, rf_opt.predict_proba(X_test)[:, 1])\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Logistic Regression ROC\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.3f)' % logit_roc_auc)\n",
    "# Plot Random Forest ROC\n",
    "plt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.3f)' % rf_opt_roc_auc)\n",
    "# Plot Base Rate ROC\n",
    "plt.plot([0, 1], [0, 1], label='Base Rate' 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Graph')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[98]:\n",
    "\n",
    "\n",
    "# Trying the gradient boosting classifier fimding the best learning rate\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(\n",
    "        n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training set): {0:.3f}\".format(\n",
    "        gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (test set): {0:.3f}\".format(\n",
    "        gb_clf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# In[113]:\n",
    "\n",
    "\n",
    "# fine tuning\n",
    "gb_classifier = GradientBoostingClassifier(random_state=0)\n",
    "param_grid = {'n_estimators': [20],\n",
    "              'learning_rate': [0.75, 1],\n",
    "              'max_features': [2],\n",
    "              'max_depth': [2]}\n",
    "\n",
    "grid_gb = GridSearchCV(gb_classifier,\n",
    "                       iid=True,\n",
    "                       return_train_score=True,\n",
    "                       param_grid=param_grid,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=10)\n",
    "\n",
    "grid_fit = grid_gb.fit(X_train, y_train)\n",
    "gb_opt = grid_fit.best_estimator_\n",
    "\n",
    "print('='*20)\n",
    "print(\"best params: \" + str(grid_gb.best_estimator_))\n",
    "print(\"best params: \" + str(grid_gb.best_params_))\n",
    "print('best score:', grid_gb.best_score_)\n",
    "print('='*20)\n",
    "\n",
    "\n",
    "# In[114]:\n",
    "\n",
    "# Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, gb_opt.predict(X_test))\n",
    "class_names = [0, 1]  # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# In[191]:\n",
    "\n",
    "\n",
    "# Classification accuracy for gb\n",
    "print('Accuracy of gradient boosting Classifier on test set: {:.2f}'.format(\n",
    "    gb_opt.score(X_test, y_test)*100))\n",
    "\n",
    "\n",
    "# In[116]:\n",
    "\n",
    "\n",
    "gb_opt.fit(X_train, y_train)\n",
    "print(classification_report(y_test, gb_opt.predict(X_test)))\n",
    "\n",
    "\n",
    "# In[182]:\n",
    "\n",
    "\n",
    "gb_opt.fit(X_train, y_train)  # fit optimised model to the training data\n",
    "probs = gb_opt.predict_proba(X_test)  # predict probabilities\n",
    "# we will only keep probabilities associated with the employee leaving\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC score using test dataset\n",
    "logit_roc_auc = roc_auc_score(y_test, probs)\n",
    "print('AUC score: %.3f' % logit_roc_auc)\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
